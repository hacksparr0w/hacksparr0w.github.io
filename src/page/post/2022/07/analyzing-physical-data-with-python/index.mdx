import { Figure } from "../../../../../component";
import { BlogPostParent } from "../../../../../partial";
import m87blackHoleImage from "./m87-black-hole.jpg";

export const parent = BlogPostParent;
export const metadata = {
  title: "Analyzing Physical Data with Python",
  subtitle: `
    Exploring the most useful concepts, techniques, and packages for physical
    data analysis with the Python programming language
  `,
  publishedOn: "July 18, 2022"
};

One of the most time-consuming exercises I got to do throughout my
undergraduate physics program was taking laboratory measurements of various
physical phenomena and analyzing the measured datapoints to prove or
disprove certain mathematical model describing the measured phenomenon. The
university courses I undertook covered the required theory behind all carried
experiments in great detail, and reproducing these experiments was not a
problem. However, courses usually focus very little on the actual data
analysis, and, as such, students tend to resort to using inefficient data
processing methods or spend much more time researching and tinkering with
various data analysis tools instead of focusing on the problem at hand.

This blog post presents basic building blocks for writing your own data
analysis scripts in the Python programming language. It contains a colorful
palette of ready-made code snippets with relevant examples of their
application in physics. We'll cover all the necessary steps of a typical
analysis procedure, from loading your data into Python's virtual memory,
through performing statistical regressions and numeric calculations, to
visualizing your results and outputting them into $\LaTeX$ documents.

It will probably take you some time before you come up with your own ideal
data analysis workflow, but I believe that by sharing some of the things I
discovered through numerous trials and errors, I can save you some headaches
and perhaps even make your time analyzing physical data a bit more enjoyable.

Please note that this is not meant to be an introduction to Python
programming and I'll be assuming at least a little knowledge of Python's
syntax on your part. If this is your first encounter with Python, I'd highly
encourage you to read through the official [Python documentation][1]. If you
are new to Python, you may still be able to learn a great deal just by playing
with the material shown here. Python is an incredibly intuitive programming
language and is made to be easily readable even for an untrained eye. Simply
copy-paste the included examples into a Python REPL, modify them to your
curiosity's accords, and see how far you get.

## Why Python?

The main difference between Python and other popular solutions for data
analysis, like, let's say, [QtiPlot][2], is that Python is a proper
programming language. It is a program for making programs. As such, it is much
more powerful in its capabilities but also has a much steeper learning curve.

Although Python was originally not designed with scientific applications in
mind, its user-friendly language design and high-level nature made it very
appealing for scientists and engineers who aren't necessarily fluent in
low-level computing details and just want to get stuff done and iterate
quickly. Over the years, Python has become extremely fashionable in the
scientific community, and its vibrant ecosystem of packages for number
crunching and data visualization makes it an excellent choice for data
analysis of any kind. To mention just one example out of many, the first-ever
picture of a black hole was
[computationally constructed using Python and NumPy][3].

<Figure
  image={m87blackHoleImage}
  caption={`
    The very first image of a supermassive black hole from the M87 galaxy. The
    image was computationally constructed using Python and various third-party
    scientific packages. Credits to the photo belong to the Event Horizon
    Telescope Collaboration.
  `}
/>

## Python development environments

Python code is just plain text, so you can use any text editor you like to
write Python programs. Text editors come with varying degrees of support for
programming languages. There are lightweight but still very powerful text
editors like [Sublime Text][4] that offer syntax-highlighting,
autocompletion, and some useful graphical features, but usually don't go
beyond that. Then there are so-called integrated development environments
(IDEs), which come with full support for your language of choice, providing
features like a built-in debugger, dependency management, test runner, and so on.
A very popular IDE for Python is [PyCharm][5]. My personal favorite is
[Visual Studio Code][6], which is a very customizable, language-agnostic IDE.

Another noteworthy development environment for Python is [Jupyter][7]. Jupyter
is a beast of its own and was purposely built for data visualization and
presentation. Jupyter comes with a web-based interface that runs your
Python code and outputs your results with pretty visuals and interactive
elements. It also lets you annotate your code and your plots with formatted
text and create beautiful documents. Jupyter notebooks are a perfect way to
bundle the results of your calculations in a nice interactive wrapping, but I
find them quite clumsy when it comes to actual coding and prototyping.

One last remark to be made when talking about Python environments: make sure
you are always using the latest stable version of Python 3, not Python 2.
Python 2 has been [deprecated since January 1, 2020][8], and things will not
work properly if you use it.

## Packages for scientific computing

Following is a list of Python packages for scientific computation we'll be
using throughout all the examples:

 - NumPy and Pandas -
 - Uncertainties, Pint, Pint-pandas -
 - SciPy
 - SymPy
 - Plotly and Kaleido

## Loading data and performing basic math

Now that we've handled all the necessary formalities, let's start with some
actual physics. We'll start slow and simple to demonstrate some basics, and
we'll gradually move on to more complex exercises.

Let's start with geometry. Suppose we have a cuboid of unknown dimensions $a$,
$b$, and $c$. We would like to measure these dimensions and then calculate the
volume $V$ of this cuboid. The volume $V$ can be calculated as

$$
  V = a \cdot b \cdot c.
$$

Simple enough, right? The next step is to take some measurements with a
standard metric ruler.

The proper way to take measurements and evaluate uncertainties with a standard
metric ruler would be the [Type A evaluation of standard uncertainty][9].
According to this standard, we need to take a sample of $N$ independent
measurements. After that, we can estimate the true value of the measured
variable as the [sample mean][10] and the standard uncertainty as the
[standard deviation of the mean][11] (sometimes referred to as standard
error). Given $N$ observations $x_i$, the sample mean $\bar x$ can be
calculated as

$$
  \bar x = \frac\{1\}\{N\} \sum_\{i=1\}^N x_i.
$$

The standard deviation of the mean $s$ can be calculated as

$$
  s = \sqrt\{\frac\{1\}\{N \cdot (N - 1)\} \sum_\{i=1\}^N (x_i - \bar x)^2 \}.
$$

For our purposes, taking ten measurements should be good enough, so we'll set
$N = 10$. To get ourselves some data without having to venture out into the
real world, we'll simulate measurements of sides of our
cuboid as sampling a [normally distributed set of values][12]. We'll define
true values for the dimensions of our cuboid as $a^* = 1.6 \\, \mathrm\{cm\}$,
$b^* = 1.6 \\, \mathrm\{cm\}$, and $c^* = 1.1 \\, \mathrm\{cm\}$. These values
are the means of our normal distributions. The standard deviation for our
normal distributions will be $\sigma = 0.05 \\, \mathrm\{cm\}$, which is one
half of the smallest measurement unit of the standard metric ruler. To
generate the measurement values with Python, we'll use the function
[`numpy.random.normal`][13]. Open up your Python REPL, import NumPy,
and try entering the following statement.

```python
>>> numpy.random.normal(1.6, 0.05, 10)
array([1.64468312, 1.67546263, 1.64805655, 1.55413015, 1.56795639,
       1.60147243, 1.59246804, 1.57452395, 1.51630531, 1.58456757])
```

This line of code produces an array of ten random values from a normally
distributed set with mean $\mu = 1.6$ and standard deviation $\sigma = 0.05$.
These values seem pretty good, but a standard metric ruler does only have a
precision of one millimeter, so we'll have to round our values with
the [`numpy.ndarray.round`][14] function.

```python
>>> numpy.random.normal(1.6, 0.05, 10).round(1)
array([1.5, 1.6, 1.5, 1.7, 1.5, 1.6, 1.6, 1.6, 1.6, 1.6])
```

This looks much more realistic. We could just work with these values directly,
but this exercise is meant to teach you to load your data from disk into
Python's memory. When carrying out a physical experiment, you'd usually write
down your measurements into a notebook or use a laptop or a tablet and save
the measured values into a file on your hard drive. We are going to use the
[`pandas.read_csv`][15] function to load our data from disk. This function
requires our data to be in the [CSV format][16]. CSV stands for
comma-separated values, it's one of the simplest and most popular formats for
storing various kinds of data. It's a text-based format for tabular data,
where rows are usually separated by a newline character and columns are
separated with comma (spaces or tabs can also be used for separating
individual columns). The following is a CSV file that I'll be using in this
exercise.

```csv
a,b,c
1.6,1.6,1.2
1.7,1.6,1.1
1.6,1.6,1.1
1.6,1.6,1.1
1.7,1.6,1.1
1.6,1.6,1.1
1.6,1.6,1.1
1.5,1.7,1.1
1.6,1.6,1.0
1.7,1.6,1.1
```

You can either generate your own data using the previously mentioned
`numpy.random.normal` function, or just copy-paste the example data and save
it into a file named _data.csv_. Now, we'll load the data using the
`pandas.read_csv`, extract the measured values into separate varaibles and use
functions [`pandas.Series.mean`][17] and [`scipy.stats.sem`][18] to calcuate
the previously defined sample mean and standard deviation of the mean for
these variables. Here's the complete solution.

```python
import pandas as pd
import scipy.stats as stats

df = pd.read_csv("./data.csv")
a, b, c = df["a"], df["b"], df["c"]

print(a.mean(), stats.sem(a))
print(b.mean(), stats.sem(b))
print(c.mean(), stats.sem(c))
```

## Physical units, uncertainties and uncertainty propagation

In the previous example, we've managed to load our measurement data from disk
and calculated their means and uncertainties. This is a pretty good start, but
there's also a lot of room for improvements. Firstly, if we run our example,
we get the following output.

```sh
1.6199999999999999 0.019999999999999983
1.61 0.009999999999999986
1.1 0.014907119849998592
```

This is not very aesthetically pleasing nor is it correct, as we should always
round our uncertainties to the first significant digit and our mean values
should be rounded to the same number of decimal places as their uncertainties.
Our script is also unaware of the physical units of these values and we might
make an error if we start doing some more complicated calculations with these
variables. Speaking of complicated calculations, we wanted to calculate the
volume $V$ of our cuboid.

Luckily for us, there's an elegant solution to all of the mentioned problems.
Enter Pint. Pint is a Python library that makes working with physical units in
Python a breeze. It also plays very well with the Uncertainty package. To
incorporate physical units and uncertainties into our script, we'll first have
to change our CSV file a bit.

```csv
a,b,c
cm,cm,cm
1.6,1.6,1.2
1.7,1.6,1.1
1.6,1.6,1.1
1.6,1.6,1.1
1.7,1.6,1.1
1.6,1.6,1.1
1.6,1.6,1.1
1.5,1.7,1.1
1.6,1.6,1.0
1.7,1.6,1.1
```

The first line of the file has been left untouched, but I've changed the
second line of the file to specify units for our variables. Now we'll also
have to rearrange our Python code a bit.

```python
import pandas as pd
import pint_pandas
import scipy.stats as stats

df = pd.read_csv("./data.csv", header=[0, 1])
df = df.pint.quantify()
a, b, c = df["a"], df["b"], df["c"]

a = a.mean().plus_minus(stats.sem(a))
b = b.mean().plus_minus(stats.sem(b))
c = c.mean().plus_minus(stats.sem(c))

print(a)
print(b)
print(c)
```

Here we've used the
[`pint_pandas.pint_array.PintDataFrameAccessor.quantify`][19] function to
make our data frame aware of our physical units. We've then used the
[`pint.facets.measurement.MeasurementQuantity.plus_minus`][20] function to
assign uncertainties to our measurements. If we run this code, the output will
look something like this.

```sh
(1.620 +/- 0.020) centimeter
(1.610 +/- 0.010) centimeter
(1.100 +/- 0.015) centimeter
```

Nice! But we're not done yet. Pint is not only capable of keeping track of our
physical units and handling their conversions, it is also able to help us with
uncertainty propagation. Pint uses the Uncertainties package to calculate
propagating uncertainties as predicted by the linear
[uncertainty propagation theory][21]. Let's try to calculate the volume of our
cuboid $V$ with its uncertainty.

[1]: https://docs.python.org/3/
[2]: https://www.qtiplot.com/
[3]: https://numpy.org/case-studies/blackhole-image/
[4]: https://www.sublimetext.com/
[5]: https://www.jetbrains.com/pycharm/
[6]: https://code.visualstudio.com/
[7]: https://jupyter.org/
[8]: https://github.com/python/devguide/pull/344
[9]: https://physics.nist.gov/cuu/Uncertainty/typea.html
[10]: https://en.wikipedia.org/wiki/Sample_mean_and_covariance
[11]: https://en.wikipedia.org/wiki/Standard_deviation#Standard_deviation_of_the_mean
[12]: https://en.wikipedia.org/wiki/Normal_distribution
[13]: https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html
[14]: https://numpy.org/doc/stable/reference/generated/numpy.ndarray.round.html
[15]: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html
[16]: https://en.wikipedia.org/wiki/Comma-separated_values
[17]: https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html
[18]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.sem.html
[19]: https://github.com/hgrecco/pint-pandas/blob/cf527e48557a1e028c6f2d4e628aa7a6cd1b30d4/pint_pandas/pint_array.py#L802
[20]: https://github.com/hgrecco/pint/blob/b0316ce54a90a25845806d7d71fb4167e8ca31f8/pint/facets/measurement/objects.py#L24
[21]: https://en.wikipedia.org/wiki/Propagation_of_uncertainty
